{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from lib.seed import seed_prefix \n",
    "import sys, os \n",
    "load_dotenv()\n",
    "seed_prefix(seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.dataset import data_split, k_fold_data_split\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data_df = pd.read_csv(os.getenv('DATASHEET_PATH'))\n",
    "data_dir = os.getenv('DATA_DIR')\n",
    "df, test_df = data_split(data_df, split_num = 5)\n",
    "\n",
    "#%% Not K-Fold \n",
    "# train_df, valid_df = data_split(train_df, split_num = 5) # 80% train, 20% valid \n",
    "\n",
    "#%% K-Fold \n",
    "folds = k_fold_data_split(df, n_splits= 5) # K-Fold 80% train, 20% valid \n",
    "\n",
    "print(f\"Fold N : Train, Valid, Test\")\n",
    "print('-'*30)\n",
    "for fdx in range(len(folds)):\n",
    "    valid_idx = folds[fdx]\n",
    "    train_idx = [idx for i, fold in enumerate(folds) if i not in [fdx] for idx in fold]\n",
    "    \n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    valid_df = df.iloc[valid_idx].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Fold {fdx+1} : {len(train_df)}, {len(valid_df)}, {len(test_df)}\")\n",
    "test_df.to_csv('./data/before_datasheet_test.csv', encoding = 'utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold N : Train, Valid, Test\n",
    "------------------------------\n",
    "Fold 1 : 1887, 489, 592\n",
    "Fold 2 : 1896, 480, 592\n",
    "Fold 3 : 1922, 454, 592\n",
    "Fold 4 : 1936, 440, 592\n",
    "Fold 5 : 1863, 513, 592\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 PID끼리는 label이 같으므로 같은 PID끼리 묶어서 label을 정한다.\n",
    "# train_df['label|0:양성, 1:중간형, 2:악성'] = \n",
    "\n",
    "# 중복갑 제거\n",
    "# train_df[]\n",
    "명수_count = train_df.iloc[train_df['PID'].drop_duplicates().index]['label|0:양성, 1:중간형, 2:악성'].value_counts()\n",
    "장수_count = train_df['label|0:양성, 1:중간형, 2:악성'].value_counts()\n",
    "\n",
    "# train_df['label|0:양성, 1:중간형, 2:악성'].value_counts()\n",
    "\n",
    "\n",
    "print(f\"장수 : 총 {np.sum(num for num in 장수_count.to_dict().values())}장\")\n",
    "for label, num in 장수_count.to_dict().items():\n",
    "    print(f\"{label} : {num}장\")\n",
    "    \n",
    "print(f\"명수 : 총 {np.sum(num for num in 명수_count.to_dict().values())}명\")\n",
    "for label, num in 명수_count.to_dict().items():\n",
    "    print(f\"{label} : {num}장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 PID끼리는 label이 같으므로 같은 PID끼리 묶어서 label을 정한다.\n",
    "명수_count = valid_df.iloc[valid_df['PID'].drop_duplicates().index]['label|0:양성, 1:중간형, 2:악성'].value_counts()\n",
    "장수_count = valid_df['label|0:양성, 1:중간형, 2:악성'].value_counts()\n",
    "\n",
    "# valid_df['label|0:양성, 1:중간형, 2:악성'].value_counts()\n",
    "\n",
    "print(f\"장수 : 총 {np.sum(num for num in 장수_count.to_dict().values())}장\")\n",
    "for label, num in 장수_count.to_dict().items():\n",
    "    print(f\"{label} : {num}장\")\n",
    "    \n",
    "print(f\"명수 : 총 {np.sum(num for num in 명수_count.to_dict().values())}명\")\n",
    "for label, num in 명수_count.to_dict().items():\n",
    "    print(f\"{label} : {num}장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 PID끼리는 label이 같으므로 같은 PID끼리 묶어서 label을 정한다.\n",
    "명수_count = test_df.iloc[test_df['PID'].drop_duplicates().index]['label|0:양성, 1:중간형, 2:악성'].value_counts()\n",
    "장수_count = test_df['label|0:양성, 1:중간형, 2:악성'].value_counts()\n",
    "\n",
    "# test_df['label|0:양성, 1:중간형, 2:악성'].value_counts()\n",
    "\n",
    "\n",
    "print(f\"장수 : 총 {np.sum(num for num in 장수_count.to_dict().values())}장\")\n",
    "for label, num in 장수_count.to_dict().items():\n",
    "    print(f\"{label} : {num}장\")\n",
    "    \n",
    "print(f\"명수 : 총 {np.sum(num for num in 명수_count.to_dict().values())}명\")\n",
    "for label, num in 명수_count.to_dict().items():\n",
    "    print(f\"{label} : {num}장\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.dataset import PCOS_Dataset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import v2\n",
    "from lib.augmentation import SpeckleNoise\n",
    "\n",
    "train_dataset = PCOS_Dataset(\n",
    "    data_filenames = train_df['filename'],\n",
    "    data_dir_path  = data_dir,\n",
    "    labels         = train_df['label|0:양성, 1:중간형, 2:악성'],\n",
    "    transform = v2.Compose([\n",
    "        v2.Resize((296, 296)), # 먼저 296x296으로 Resize\n",
    "        # v2.CenterCrop(224),           # 224x224 중앙 자르기 -> 0.7977\n",
    "        # Augmenttation 추가\n",
    "        # RandomEqualize(p=0.5),    # Histogram Equalized\n",
    "        v2.RandomRotation(degrees = 15), # 랜덤 회전\n",
    "        v2.RandomHorizontalFlip(p = 0.5),    # 랜덤 수평 뒤집기\n",
    "        v2.RandomVerticalFlip(p = 0.5), # 랜덤 수직 뒤집기\n",
    "        v2.RandomResizedCrop(224),           # 224x224 렌담 중앙 자르기 -> 0.8089\n",
    "\n",
    "        # Default Augmentation\n",
    "        v2.Grayscale(num_output_channels=3),  # 3채널 회색변환 (RGB 형태 유지)\n",
    "        v2.ToTensor(),                # 텐서 변환 \n",
    "        v2.RandomApply([\n",
    "            v2.GaussianNoise(mean = 0, sigma = 0.1, clip = True)], p=0.5), # 가우시안 노이즈\n",
    "            # [Refer] SpeckleNoise : Automatic ovarian tumors recognition system based on ensemble convolutional neural network with ultrasound imaging\n",
    "            SpeckleNoise(noise_level = 0.05) # Ultraosound Speckle Noise\n",
    "            # v2.RandomApply([v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.))], p=0.5), # 가우시안 Blur\n",
    "        # T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet 정규화 -> 0.7119\n",
    "    ])\n",
    ")\n",
    "\n",
    "valid_dataset = PCOS_Dataset(\n",
    "    data_filenames = valid_df['filename'],\n",
    "    data_dir_path  = data_dir,\n",
    "    labels         = valid_df['label|0:양성, 1:중간형, 2:악성'],\n",
    "    transform = v2.Compose([\n",
    "        v2.Resize((224, 224)),        # 검증 시에는 224로만 Resize (예시)\n",
    "        v2.Grayscale(num_output_channels=3),\n",
    "        v2.ToTensor(),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loader 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 16, shuffle = False)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize = (12, 12))\n",
    "fig.suptitle('PCOS Dataset Augmentation Example', fontsize = 16)\n",
    "for i in range(16):\n",
    "    axes[i//4, i%4].imshow(X[i].cpu().permute(1, 2, 0).numpy())\n",
    "    axes[i//4, i%4].set_title(f'Label: {y[i].item()}')\n",
    "    axes[i//4, i%4].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os, sys \n",
    "from glob import glob \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "for img_path in glob(os.environ[\"DATA_DIR\"]+'/*'):\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # img center crop 0.8 ratio\n",
    "    left_up = (img.size[0] * 0.1, img.size[1] * 0.1)\n",
    "    left_down = (img.size[0] * 0.1, img.size[1] * 0.9)\n",
    "    right_up = (img.size[0] * 0.9, img.size[1] * 0.1)\n",
    "    right_down = (img.size[0] * 0.9, img.size[1] * 0.9)\n",
    "    \n",
    "    img = img.crop((left_up[0], left_up[1], right_down[0], right_down[1]))\n",
    "    \n",
    "    img.save(img_path.replace(\"Dataset\", \"Dataset_center_crop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys, os \n",
    "from glob import glob\n",
    "\n",
    "\n",
    "filepaths = glob(\"/mnt/hdd/octc/BACKUP/Dataset/*\")\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "df =pd.read_csv(\"./data/datasheet.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for filepath in filepaths:\n",
    "    filename = os.path.basename(filepath).replace('.png', '')\n",
    "\n",
    "    label = df[df['filename'] == filename]['label|0:양성, 1:중간형, 2:악성'].values[0]\n",
    "    \n",
    "    if label == 0:\n",
    "        save_to_dir = \"/home/eiden/eiden/otion_project/kohya_ss/dataset/images/ovarian_cyst_data/1_ovarian cyst benigns/\"\n",
    "        dignosis_type = \"benign\"\n",
    "    elif label == 1:\n",
    "        save_to_dir = \"/home/eiden/eiden/otion_project/kohya_ss/dataset/images/ovarian_cyst_data/2_ovarian cyst borderlines/\"\n",
    "        dignosis_type = \"borderline\"\n",
    "    else:\n",
    "        save_to_dir = \"/home/eiden/eiden/otion_project/kohya_ss/dataset/images/ovarian_cyst_data/3_ovarian cyst malignants/\"\n",
    "        dignosis_type = \"malignant\"\n",
    "        \n",
    "        \n",
    "    shutil.copy(filepath, save_to_dir)\n",
    "    \n",
    "    with open(f\"{save_to_dir}/{filename}.txt\", 'w') as f:\n",
    "        f.write(f\"An ovarian ultrasound image showing {dignosis_type} characteristic\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
