import pandas as pd

def create_label_mapping(label_df, label_col):
    unique_labels = sorted(label_df[label_col].unique())
    mapping = {label: idx for idx, label in enumerate(unique_labels)}
    print("Label Mapping:", mapping)
    return mapping

def normalize_label(label):
    # "PCOS,NORMAL" â†’ ë©€í‹°ë¼ë²¨ â†’ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(label, str) and "," in label:
        return label.split(",")
    return label

from sklearn.model_selection import train_test_split, StratifiedKFold


def stratified_split_by_pid(df, pid_col="pid", label_col="label", seed=42):
    # PID ê¸°ë°˜ ê·¸ë£¹í•‘
    pid_groups = df.groupby(pid_col)[label_col].agg(lambda x: x.iloc[0])
    pid_groups = pid_groups.reset_index()

    # Train 70%, Temp 30%
    train_pid, temp_pid = train_test_split(
        pid_groups,
        test_size=0.3,
        stratify=pid_groups[label_col],
        random_state=seed
    )

    # Tempì„ ë‹¤ì‹œ Val 10%, Test 20%ë¡œ ë‚˜ëˆ„ê¸° (Temp = 30 â†’ Val 10, Test 20)
    val_pid, test_pid = train_test_split(
        temp_pid,
        test_size=2/3,     # (20% / 30%) = 2/3
        stratify=temp_pid[label_col],
        random_state=seed
    )

    # PIDë¡œ ì›ë³¸ df í•„í„°ë§
    train_df = df[df[pid_col].isin(train_pid[pid_col])]
    val_df = df[df[pid_col].isin(val_pid[pid_col])]
    test_df = df[df[pid_col].isin(test_pid[pid_col])]

    print("PID Split Result:")
    print("Train:", len(train_df), "Val:", len(val_df), "Test:", len(test_df))

    return train_df, val_df, test_df

def stratified_pid_kfold(df, n_splits=5, pid_col="pid", label_col="label", seed=42):
    """
    Returns list of (train_df, val_df) for each fold.
    """

    # PID ë‹¨ìœ„ë¡œ label ëŒ€í‘œê°’ ìƒì„±
    pid_groups = df.groupby(pid_col)[label_col].first().reset_index()

    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)

    folds = []

    for fold_idx, (train_pid_index, val_pid_index) in enumerate(
        skf.split(pid_groups[pid_col], pid_groups[label_col])
    ):
        train_pids = pid_groups.iloc[train_pid_index][pid_col].values
        val_pids = pid_groups.iloc[val_pid_index][pid_col].values

        train_df = df[df[pid_col].isin(train_pids)]
        val_df = df[df[pid_col].isin(val_pids)]

        print(f"[Fold {fold_idx}] Train: {len(train_df)}, Val: {len(val_df)}")

        folds.append((train_df, val_df))

    return folds


import torch
from torch.utils.data import WeightedRandomSampler

def create_weighted_sampler(df, label_col):
    class_counts = df[label_col].value_counts()
    weight_map = 1.0 / class_counts
    weights = df[label_col].map(weight_map).values
    weights = torch.DoubleTensor(weights)
    sampler = WeightedRandomSampler(weights, len(weights), replacement=True)
    return sampler


import os
from PIL import Image
from torch.utils.data import Dataset
class PCOSDataset(Dataset):
    def __init__(self, df, data_root, filename_col, label_col, label_mapping,
                 transform=None, multi_label=False):
        
        self.df = df.reset_index(drop=True)
        self.data_root = data_root
        self.filename_col = filename_col
        self.label_col = label_col
        self.transform = transform
        self.label_mapping = label_mapping
        self.multi_label = multi_label

    def __len__(self):
        return len(self.df)

    def load_image(self, path):
        if not os.path.exists(path):
            print(f"[Warning] Image not found: {path} â€” skipping.")
            raise FileNotFoundError(f"Image not found: {path}")
        
        return Image.open(path).convert("RGB")

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        filename = row[self.filename_col]
        img_path = os.path.join(self.data_root, filename + '.png')

        image = self.load_image(img_path)

        # augmentation ì ìš©
        if self.transform:
            image = self.transform(image)

        # multi-label / multi-class ì§€ì›
        label = normalize_label(row[self.label_col])

        if self.multi_label:
            # multi-label: ['PCOS','NORMAL'] â†’ multi-hot ë²¡í„°ë¡œ ë³€í™˜ ë“± í™•ì¥ ê°€ëŠ¥
            numeric_label = [self.label_mapping[l] for l in label]
        else:
            numeric_label = self.label_mapping[label]

        return image, numeric_label


class HFVisionDataset(torch.utils.data.Dataset):
    def __init__(self, base_dataset, processor = None):
        self.base = base_dataset
        self.processor = processor

    def __len__(self):
        return len(self.base)

    def __getitem__(self, idx):
        image, label = self.base[idx]

        # PIL or tensor â†’ processor(pixel_values=...) ë³€í™˜

        # ë°°ì¹˜ ì°¨ì› ì œê±°
        if self.processor:
            encoded = self.processor(images=image, return_tensors="pt")
            return {
                "pixel_values": encoded.pixel_values,                             # Trainerê°€ ì´ í‚¤ë¥¼ ì‚¬ìš©
                "labels": torch.tensor(label, dtype=torch.long),   # ì •ìˆ˜ ë ˆì´ë¸”
            }
        else:
            return {
            "pixel_values": image,                             # Trainerê°€ ì´ í‚¤ë¥¼ ì‚¬ìš©
            "labels": torch.tensor(label, dtype=torch.long),   # ì •ìˆ˜ ë ˆì´ë¸”
            }



import pandas as pd 
from utils.transform import get_transform, SpeckleNoise, AddGaussianNoise
from torch.utils.data import DataLoader
from torchvision import transforms

def default_run(data_root_dir, label_path):
    label_df = pd.read_csv(label_path)

    train_tf, val_tf = get_transform(
        train_transform=[
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.RandomAffine(degrees=0, translate=(0.05,0.05), scale=(0.95,1.05)),
            transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),
            # AddGaussianNoise(std=0.02),
            # SpeckleNoise(noise_factor=0.1),
        ]
    )

    label_mapping = create_label_mapping(label_df, "label")

    # 2) Train / Val / Test split (PID ë‹¨ìœ„ stratified 7:1:2)
    train_df, val_df, test_df = stratified_split_by_pid(label_df)

    # 3) Tune = Train + Val (80%)
    tune_df = pd.concat([train_df, val_df]).reset_index(drop=True)

    # 4) K-FoldëŠ” tune_df ì— ëŒ€í•´ì„œë§Œ ì ìš©
    folds = stratified_pid_kfold(tune_df, n_splits=5) # [ADD] K-Fold Cross Validation ì¶”ê°€
    kfold_loaders = []

    for fold_idx, (train_df, val_df) in enumerate(folds):
        train_dataset = PCOSDataset(train_df, data_root_dir, "filename", "label",
                                    label_mapping, transform=train_tf)
        val_dataset   = PCOSDataset(val_df,   data_root_dir, "filename", "label",
                                    label_mapping, transform=val_tf)

        sampler = create_weighted_sampler(train_df, "label")

        train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)
        val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)

        kfold_loaders.append((train_loader, val_loader))

        print(f"Fold {fold_idx} loader ready.")

    # Test loaderëŠ” ë”°ë¡œ êµ¬ì„±
    test_dataset = PCOSDataset(test_df, data_root_dir, "filename", "label", label_mapping, transform=val_tf)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)
    
    return kfold_loaders, test_loader


from PIL import Image
import torch
from torch.utils.data import Dataset
from torchvision import transforms
import os

def generate_bag_dict(df, image_root_dir):
    bag_dict = {}
    for pid, group in df.groupby("pid"):
        files = group["filename"].tolist()
        label = group["label"].iloc[0] # pidì˜ label ì€ ëª¨ë‘ ë™ì¼í•¨(ê¸°ì¡´&ë³€ê²½ ëª¨ë‘ í™•ì¸ì™„ë£Œ)
        bag_dict[pid] = {
            "files": files,
            "label": label
        }
        
    for pid in bag_dict:
        bag_dict[pid]['paths'] = {f"{image_root_dir}/{fname}.png" for fname in bag_dict[pid]['files']}
    return bag_dict



class PCOSMILDataset(Dataset):
    def __init__(self, df, image_root_dir, transform=None, label_mapping=None):
        """
        df â†’ fold dataframe
        label_mapping â†’ {raw_label â†’ numeric_label}
        """
        self.bag_dict = generate_bag_dict(df, image_root_dir)
        self.pids = list(self.bag_dict.keys())
        self.transform = transform
        self.label_mapping = label_mapping   # ğŸ”¥ label mapping ì ìš©

    def __len__(self):
        return len(self.pids)

    def load_image(self, path):
        if not os.path.exists(path):
            print(f"[Warning] Image not found: {path}")
            raise FileNotFoundError(f"Image not found: {path}")
        return Image.open(path).convert("RGB")

    def __getitem__(self, idx):
        pid = self.pids[idx]
        bag = self.bag_dict[pid]

        img_paths = bag["paths"]
        raw_label = bag["label"]            # ğŸ”¥ raw label (ì˜ˆ: 0 or 2)

        # -------------------------------
        # ğŸ”¥ label_mapping ì ìš© (ì¤‘ìš”)
        # -------------------------------
        if self.label_mapping is not None:
            try:
                numeric_label = self.label_mapping[raw_label]
            except KeyError:
                raise ValueError(f"[ERROR] raw_label={raw_label} not found in label_mapping={self.label_mapping}")
        else:
            numeric_label = raw_label   # fallback

        images = []
        for img_path in img_paths:
            img = self.load_image(img_path)
            if self.transform:
                img = self.transform(img)
            images.append(img)

        if len(images) == 0:
            raise ValueError(f"No images found for pid={pid}")

        bag_tensor = torch.stack(images, dim=0)

        return {
            "filename": bag["files"],
            "images": bag_tensor,
            "label": torch.tensor(numeric_label, dtype=torch.long)  # ğŸ”¥ CrossEntropyLoss safe
        }